{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b7bb97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import cvzone\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd9a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video feed \n",
    "cap = cv2.VideoCapture(\"carParkingInput.mp4\")\n",
    "\n",
    "#Loading the ROI from parkingSlotPosition file\n",
    "with open('parkingSlotPosition', 'rb') as f:\n",
    "    posList = pickle.load(f)\n",
    "    \n",
    "#Define width and height\n",
    "width, height = 107, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eed49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkParkingSpace(imgPro):\n",
    "    spaceCounter = 0\n",
    "    for pos in posList:\n",
    "        x, y = pos\n",
    "        \n",
    "        #Crop the image based on ROI\n",
    "        imgCrop = imgPro[y:y + height, x:x + width]\n",
    "        \n",
    "        #Counting the pixel values from cropped image\n",
    "        count = cv2.countNonZero(imgCrop)\n",
    "        if count < 900:\n",
    "            color = (0, 255, 0)\n",
    "            thickness = 5\n",
    "            spaceCounter += 1\n",
    "        else:\n",
    "            color = (0, 0, 255)\n",
    "            thickness = 2\n",
    "            \n",
    "        #Draw the rectangle based on the condition defined above\n",
    "        cv2.rectangle(img, pos, (pos[0] + width, pos[1] + height), color, thickness)\n",
    "        \n",
    "        #Display the avaliable parking slot count/total parking slot count\n",
    "        cvzone.putTextRect(img, f'Free: {spaceCounter}/{len(posList)}', (100, 50), scale=3, thickness=5, offset=20, colorR=(0,200,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592d903",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    #Looping the video \n",
    "    if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "        \n",
    "    #Reading frame by frame from the video\n",
    "    success, img = cap.read()\n",
    "    \n",
    "    #Converting to gray scale image\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    imgBlur = cv2.GaussianBlur(imgGray, (3, 3), 1)\n",
    "    \n",
    "    # Applying blur to the image\n",
    "    # Applying threshold to the image\n",
    "    imgThreshold = cv2.adaptiveThreshold(imgBlur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 25, 16)\n",
    "    imgMedian = cv2.medianBlur(imgThreshold, 5) #Applying blur to the image\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    imgDilate = cv2.dilate(imgMedian, kernel, iterations=1)\n",
    "    \n",
    "    #Passing dilate image to the function \n",
    "    checkParkingSpace(imgDilate)\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c7c1c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d5496502",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ae963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
